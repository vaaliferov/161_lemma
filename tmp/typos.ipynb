{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58fc59f-92ce-4a46-b1eb-464299c66c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lemma.parse import parse_dict\n",
    "from lemma.utils import dump_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e8bf21-60be-4b4a-9f1f-4dfa16556eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, cols = parse_dict('data/dict.opcorpora.xml')\n",
    "df = pd.DataFrame(data['lemmas'], columns=cols['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38099a3e-c4dc-4c2c-a5ae-660b917a2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(df['word'].to_list())\n",
    "dump_lines(words, 'data/words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bdc5397-cb67-4596-b288-6d22c85dd877",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = [f'{w} 1' for w in words]\n",
    "dump_lines(freq_dict, 'data/freq_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097c6b6-3aa6-46dc-b54e-b24474c28c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eae59ab-6298-4a3a-82b0-70a4c0de08c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install symspellpy\n",
    "from symspellpy import SymSpell\n",
    "from symspellpy import Verbosity\n",
    "\n",
    "ss = SymSpell()\n",
    "# ss.create_dictionary('data/corpus.txt')\n",
    "ss.load_dictionary('data/freq_dict.txt', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba51fd8-3821-4e3f-94c7-511320a7fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_params = {\n",
    "    'max_edit_distance': 2,\n",
    "    'verbosity': Verbosity.CLOSEST\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd27882-6974-456a-8066-f2173786884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.8 µs ± 442 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ss.lookup('надежный', **lookup_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e94fa70f-05aa-427f-8ac5-5b3a72ec94a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "падежный, 1, 2\n",
      "надёжный, 1, 2\n"
     ]
    }
   ],
   "source": [
    "for s in ss.lookup('надежный', **lookup_params): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb87b4-3067-4de5-a9bc-70051f72bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in ss.lookup('рабогтает', **lookup_params): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0455f010-a5a9-43de-a191-54a79abd17fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "администраторам, 2, 1\n",
      "администраторами, 2, 1\n"
     ]
    }
   ],
   "source": [
    "for s in ss.lookup('админисраторамм', **lookup_params): print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70563f-489c-45ef-9e67-2feaf865827c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d72821c-1b0f-42a0-aa45-af5644570ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "class NFA(object):\n",
    "    \n",
    "    ANY = object()\n",
    "    EPSILON = object()\n",
    "    \n",
    "    def __init__(self, start_state):\n",
    "        self.transitions = {}\n",
    "        self.final_states = set()\n",
    "        self._start_state = start_state\n",
    "    \n",
    "    @property\n",
    "    def start_state(self):\n",
    "        return frozenset(self._expand(set([self._start_state])))\n",
    "    \n",
    "    def add_transition(self, src, input, dest):\n",
    "        self.transitions.setdefault(src, {}).setdefault(input, set()).add(dest)\n",
    "\n",
    "    def add_final_state(self, state):\n",
    "        self.final_states.add(state)\n",
    "    \n",
    "    def is_final(self, states):\n",
    "        return self.final_states.intersection(states)\n",
    "    \n",
    "    def _expand(self, states):\n",
    "        frontier = set(states)\n",
    "        while frontier:\n",
    "            state = frontier.pop()\n",
    "            new_states = self.transitions.get(state, {}).get(NFA.EPSILON, set()).difference(states)\n",
    "            frontier.update(new_states)\n",
    "            states.update(new_states)\n",
    "        return states\n",
    "    \n",
    "    def next_state(self, states, input):\n",
    "        dest_states = set()\n",
    "        for state in states:\n",
    "            state_transitions = self.transitions.get(state, {})\n",
    "            dest_states.update(state_transitions.get(input, []))\n",
    "            dest_states.update(state_transitions.get(NFA.ANY, []))\n",
    "        return frozenset(self._expand(dest_states))\n",
    "    \n",
    "    def get_inputs(self, states):\n",
    "        inputs = set()\n",
    "        for state in states:\n",
    "            inputs.update(self.transitions.get(state, {}).keys())\n",
    "        return inputs\n",
    "    \n",
    "    def to_dfa(self):\n",
    "        dfa = DFA(self.start_state)\n",
    "        frontier = [self.start_state]\n",
    "        seen = set()\n",
    "        while frontier:\n",
    "            current = frontier.pop()\n",
    "            inputs = self.get_inputs(current)\n",
    "            for input in inputs:\n",
    "                if input == NFA.EPSILON: continue\n",
    "                new_state = self.next_state(current, input)\n",
    "                if new_state not in seen:\n",
    "                    frontier.append(new_state)\n",
    "                    seen.add(new_state)\n",
    "                    if self.is_final(new_state):\n",
    "                        dfa.add_final_state(new_state)\n",
    "                if input == NFA.ANY:\n",
    "                    dfa.set_default_transition(current, new_state)\n",
    "                else:\n",
    "                    dfa.add_transition(current, input, new_state)\n",
    "        return dfa\n",
    "\n",
    "class DFA(object):\n",
    "    def __init__(self, start_state):\n",
    "        self.start_state = start_state\n",
    "        self.transitions = {}\n",
    "        self.defaults = {}\n",
    "        self.final_states = set()\n",
    "    \n",
    "    def add_transition(self, src, input, dest):\n",
    "        self.transitions.setdefault(src, {})[input] = dest\n",
    "    \n",
    "    def set_default_transition(self, src, dest):\n",
    "        self.defaults[src] = dest\n",
    "    \n",
    "    def add_final_state(self, state):\n",
    "        self.final_states.add(state)\n",
    "\n",
    "    def is_final(self, state):\n",
    "        return state in self.final_states\n",
    "    \n",
    "    def next_state(self, src, input):\n",
    "        state_transitions = self.transitions.get(src, {})\n",
    "        return state_transitions.get(input, self.defaults.get(src, None))\n",
    "\n",
    "    def next_valid_string(self, input):\n",
    "        state = self.start_state\n",
    "        stack = []\n",
    "        \n",
    "        # Evaluate the DFA as far as possible\n",
    "        for i, x in enumerate(input):\n",
    "            stack.append((input[:i], state, x))\n",
    "            state = self.next_state(state, x)\n",
    "            if not state: break\n",
    "        else:\n",
    "            stack.append((input[:i+1], state, None))\n",
    "\n",
    "        if self.is_final(state):\n",
    "            # Input word is already valid\n",
    "            return input\n",
    "        \n",
    "        # Perform a 'wall following' search for the lexicographically smallest\n",
    "        # accepting state.\n",
    "        while stack:\n",
    "            path, state, x = stack.pop()\n",
    "            x = self.find_next_edge(state, x)\n",
    "            if x:\n",
    "                path += x\n",
    "                state = self.next_state(state, x)\n",
    "                if self.is_final(state):\n",
    "                    return path\n",
    "                stack.append((path, state, None))\n",
    "        return None\n",
    "\n",
    "    def find_next_edge(self, s, x):\n",
    "        if x is None:\n",
    "            x = u'\\0'\n",
    "        else:\n",
    "            x = chr(ord(x) + 1)\n",
    "        state_transitions = self.transitions.get(s, {})\n",
    "        if x in state_transitions or s in self.defaults:\n",
    "            return x\n",
    "        labels = sorted(state_transitions.keys())\n",
    "        pos = bisect.bisect_left(labels, x)\n",
    "        if pos < len(labels):\n",
    "            return labels[pos]\n",
    "        return None\n",
    "\n",
    "def levenshtein_automata(term, k):\n",
    "    nfa = NFA((0, 0))\n",
    "    for i, c in enumerate(term):\n",
    "        for e in range(k + 1):\n",
    "            # Correct character\n",
    "            nfa.add_transition((i, e), c, (i + 1, e))\n",
    "            if e < k:\n",
    "                # Deletion\n",
    "                nfa.add_transition((i, e), NFA.ANY, (i, e + 1))\n",
    "                # Insertion\n",
    "                nfa.add_transition((i, e), NFA.EPSILON, (i + 1, e + 1))\n",
    "                # Substitution\n",
    "                nfa.add_transition((i, e), NFA.ANY, (i + 1, e + 1))\n",
    "    for e in range(k + 1):\n",
    "        if e < k:\n",
    "            nfa.add_transition((len(term), e), NFA.ANY, (len(term), e + 1))\n",
    "        nfa.add_final_state((len(term), e))\n",
    "    return nfa\n",
    "\n",
    "def find_all_matches(word, k, lookup_func):\n",
    "    \"\"\"Uses lookup_func to find all words within levenshtein distance k of word.\n",
    "    \n",
    "    Args:\n",
    "        word: The word to look up\n",
    "        k: Maximum edit distance\n",
    "        lookup_func: A single argument function that returns the first word in the\n",
    "            database that is greater than or equal to the input argument.\n",
    "    Yields:\n",
    "        Every matching word within levenshtein distance k from the database.\n",
    "    \"\"\"\n",
    "    lev = levenshtein_automata(word, k).to_dfa()\n",
    "    match = lev.next_valid_string(u'\\0')\n",
    "    while match:\n",
    "        next = lookup_func(match)\n",
    "        if not next:\n",
    "            return\n",
    "        if match == next:\n",
    "            yield match\n",
    "            next = next + u'\\0'\n",
    "        match = lev.next_valid_string(next)\n",
    "\n",
    "class Matcher(object):\n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        self.probes = 0\n",
    "    def __call__(self, w):\n",
    "        self.probes += 1\n",
    "        pos = bisect.bisect_left(self.l, w)\n",
    "        if pos < len(self.l):\n",
    "            return self.l[pos]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a13404-d1f5-40f4-9ef9-dfd9d0559458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemma.utils import load_lines\n",
    "matcher = Matcher(load_lines('data/words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6216ee7-8900-4f74-b0bc-59d60060b9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['надёжный', 'падежный']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(find_all_matches('надежный', 1, matcher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce25e63b-ea05-4d14-beb7-6a96e2b6abb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['администраторам', 'администраторами']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(find_all_matches('админисраторамм', 2, matcher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2f3dbec-1d1d-484b-87ca-25d9caca4583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 ms ± 875 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit list(find_all_matches('админисраторамм', 2, matcher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5f2f2-2981-44c5-b08a-b9cc26f64555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91068314-eeb6-4d77-b803-4be93ef57e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apt install swig3.0\n",
    "# pip install jamspell\n",
    "# !wget https://github.com/bakwc/JamSpell-models/raw/master/ru.tar.gz\n",
    "# !tar -xvf ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111284e6-cdb3-49ed-baf9-c933535d86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jamspell\n",
    "jsp = jamspell.TSpellCorrector()\n",
    "assert jsp.LoadLangModel('ru_small.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c775440-42b1-4ab9-82cd-048f336c5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsp.FixFragment(\"надежныр механизм\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dawg_env",
   "language": "python",
   "name": "dawg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
